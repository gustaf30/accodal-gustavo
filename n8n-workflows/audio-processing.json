{
  "name": "Audio Transcription Processing",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "process-audio",
        "responseMode": "responseNode",
        "options": {
          "rawBody": true
        }
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [250, 300],
      "webhookId": "audio-upload"
    },
    {
      "parameters": {
        "jsCode": "// Extract audio file data from webhook and prepare binary\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const body = item.json.body || item.json;\n  \n  let fileData = {\n    filename: body.filename || 'audio.mp3',\n    mime_type: body.mime_type || body.content_type || 'audio/mpeg',\n    file_url: body.file_url || null,\n    base64_content: body.base64_content || body.file_content || null,\n    user_id: body.user_id || null,\n    language: body.language || 'en',\n    metadata: body.metadata || {}\n  };\n  \n  if (!fileData.base64_content && !fileData.file_url) {\n    throw new Error('Either base64_content or file_url is required');\n  }\n  \n  const validAudioTypes = ['audio/mpeg', 'audio/mp3', 'audio/wav', 'audio/wave', 'audio/webm', 'audio/ogg', 'audio/flac', 'audio/m4a'];\n  if (!validAudioTypes.some(type => fileData.mime_type.toLowerCase().includes(type.split('/')[1]))) {\n    throw new Error('Invalid audio type: ' + fileData.mime_type + '. Supported: MP3, WAV, WebM, OGG, FLAC, M4A');\n  }\n  \n  // Return with binary data for Whisper API\n  if (fileData.base64_content) {\n    results.push({\n      json: fileData,\n      binary: {\n        audio: {\n          data: fileData.base64_content,\n          mimeType: fileData.mime_type,\n          fileName: fileData.filename\n        }\n      }\n    });\n  } else {\n    results.push({ json: fileData });\n  }\n}\n\nreturn results;"
      },
      "id": "parse-input",
      "name": "Parse Audio Input",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [470, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/audio/transcriptions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": []
        },
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "audio"
            },
            {
              "parameterType": "formData",
              "name": "model",
              "value": "whisper-1"
            },
            {
              "parameterType": "formData",
              "name": "response_format",
              "value": "verbose_json"
            },
            {
              "parameterType": "formData",
              "name": "language",
              "value": "={{ $json.language }}"
            }
          ]
        },
        "options": {
          "timeout": 180000
        }
      },
      "id": "whisper-transcription",
      "name": "OpenAI Whisper Transcription",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [690, 300],
      "credentials": {
        "httpHeaderAuth": {
          "id": "openai-credential",
          "name": "OpenAI API Key"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare OpenAI NLP payload for entity extraction\nconst items = $input.all();\nconst prevItems = $('Parse Audio Input').all();\nconst results = [];\n\nconst systemPrompt = `You are a financial data extraction expert. Analyze the following audio transcription and extract:\n1. Any Social Security Numbers mentioned (format: XXX-XX-XXXX)\n2. Any Tax IDs or EINs (format: XX-XXXXXXX)\n3. Income figures and amounts\n4. Dates mentioned\n5. Names of people or companies\n6. Any tax-related terms or document references\n\nRespond ONLY with valid JSON:\n{\n  \"ssn_mentions\": [\"masked SSN like XXX-XX-1234\"],\n  \"tax_id_mentions\": [\"masked EIN like XX-XXX1234\"],\n  \"income_figures\": [{\"amount\": 50000, \"context\": \"annual salary\"}],\n  \"dates\": [\"2024-01-15\"],\n  \"names\": [\"John Smith\", \"Acme Corp\"],\n  \"document_references\": [\"W-2\", \"1099\"],\n  \"key_topics\": [\"tax filing\", \"deductions\"],\n  \"summary\": \"Brief summary of the audio content\"\n}`;\n\nfor (let i = 0; i < items.length; i++) {\n  const whisperResult = items[i].json;\n  const inputData = prevItems[i].json;\n  \n  const transcriptionText = whisperResult.text || '';\n  \n  results.push({\n    json: {\n      ...inputData,\n      transcription: transcriptionText,\n      whisper_duration: whisperResult.duration || null,\n      whisper_language: whisperResult.language || inputData.language,\n      whisper_segments: whisperResult.segments || [],\n      openai_payload: {\n        model: 'gpt-4o-mini',\n        messages: [\n          { role: 'system', content: systemPrompt },\n          { role: 'user', content: 'Extract financial and tax-related entities from this transcription:\\n\\n' + transcriptionText }\n        ],\n        max_tokens: 2048,\n        temperature: 0.1\n      }\n    }\n  });\n}\n\nreturn results;"
      },
      "id": "prepare-nlp-payload",
      "name": "Prepare NLP Payload",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [910, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.openai_payload) }}",
        "options": {}
      },
      "id": "nlp-extraction",
      "name": "NLP Entity Extraction",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1130, 300],
      "credentials": {
        "httpHeaderAuth": {
          "id": "openai-credential",
          "name": "OpenAI API Key"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Process NLP extraction results\nconst items = $input.all();\nconst prevItems = $('Prepare NLP Payload').all();\nconst results = [];\n\nfor (let i = 0; i < items.length; i++) {\n  const item = items[i];\n  const inputData = prevItems[i].json;\n  \n  let entities;\n  try {\n    let responseText = item.json.choices?.[0]?.message?.content || '{}';\n    \n    if (responseText.includes('```json')) {\n      responseText = responseText.replace(/```json\\n?/g, '').replace(/```\\n?/g, '');\n    } else if (responseText.includes('```')) {\n      responseText = responseText.replace(/```\\n?/g, '');\n    }\n    \n    entities = JSON.parse(responseText.trim());\n  } catch (e) {\n    entities = {\n      ssn_mentions: [],\n      tax_id_mentions: [],\n      income_figures: [],\n      dates: [],\n      names: [],\n      document_references: [],\n      key_topics: [],\n      summary: 'Entity extraction failed',\n      parse_error: e.message\n    };\n  }\n  \n  // Mask sensitive data in transcription\n  let maskedTranscription = inputData.transcription || '';\n  maskedTranscription = maskedTranscription.replace(/\\b\\d{3}[-\\s]?\\d{2}[-\\s]?\\d{4}\\b/g, '[SSN REDACTED]');\n  maskedTranscription = maskedTranscription.replace(/\\b\\d{2}[-\\s]?\\d{7}\\b/g, '[EIN REDACTED]');\n  \n  // Calculate confidence from Whisper segments\n  let confidence = null;\n  if (inputData.whisper_segments && inputData.whisper_segments.length > 0) {\n    const avgLogProb = inputData.whisper_segments.reduce((sum, s) => sum + (s.avg_logprob || 0), 0) / inputData.whisper_segments.length;\n    confidence = Math.exp(avgLogProb);\n  }\n  \n  results.push({\n    json: {\n      filename: inputData.filename,\n      file_url: inputData.file_url,\n      mime_type: inputData.mime_type,\n      user_id: inputData.user_id,\n      transcription: maskedTranscription,\n      duration_seconds: inputData.whisper_duration,\n      language: inputData.whisper_language,\n      confidence: confidence,\n      extracted_entities: entities,\n      metadata: inputData.metadata\n    }\n  });\n}\n\nreturn results;"
      },
      "id": "process-results",
      "name": "Process Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1350, 300]
    },
    {
      "parameters": {
        "jsCode": "// Prepare Supabase payload\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const data = item.json;\n  results.push({\n    json: {\n      ...data,\n      supabase_payload: {\n        audio: {\n          filename: data.filename,\n          file_url: data.file_url,\n          mime_type: data.mime_type,\n          duration_seconds: data.duration_seconds ? Math.round(data.duration_seconds) : null,\n          transcription: data.transcription,\n          extracted_entities: data.extracted_entities,\n          confidence: data.confidence,\n          language: data.language\n        },\n        user_id: data.user_id\n      }\n    }\n  });\n}\n\nreturn results;"
      },
      "id": "prepare-supabase-payload",
      "name": "Prepare Supabase Payload",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1570, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://lkyixaippdmtjyiztuzw.supabase.co/functions/v1/validate-audio",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "apikey",
              "value": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImxreWl4YWlwcGRtdGp5aXp0dXp3Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2OTcwMjY4OSwiZXhwIjoyMDg1Mjc4Njg5fQ.nD4GhFIFXs-1qvdc42vAO1uumgTfGgiABsB9OgrOJHo"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.supabase_payload) }}",
        "options": {}
      },
      "id": "store-in-supabase",
      "name": "Validate & Store Audio",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1790, 300],
      "credentials": {
        "httpHeaderAuth": {
          "id": "supabase-credential",
          "name": "Supabase Service Key"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "condition-success",
              "leftValue": "={{ $json.success }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "check-success",
      "name": "Check Success",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [2010, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify({ success: true, audio_id: $json.audio_id, warnings: $json.warnings, extracted_entities: $('Process Results').first().json.extracted_entities, transcription_preview: $('Process Results').first().json.transcription.substring(0, 200) + '...' }) }}"
      },
      "id": "success-response",
      "name": "Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [2230, 200]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify({ success: false, error: $json.error || $json.errors || 'Audio processing failed' }) }}",
        "options": {
          "responseCode": 422
        }
      },
      "id": "error-response",
      "name": "Error Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [2230, 400]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Parse Audio Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Audio Input": {
      "main": [
        [
          {
            "node": "OpenAI Whisper Transcription",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Whisper Transcription": {
      "main": [
        [
          {
            "node": "Prepare NLP Payload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare NLP Payload": {
      "main": [
        [
          {
            "node": "NLP Entity Extraction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "NLP Entity Extraction": {
      "main": [
        [
          {
            "node": "Process Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Results": {
      "main": [
        [
          {
            "node": "Prepare Supabase Payload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Supabase Payload": {
      "main": [
        [
          {
            "node": "Validate & Store Audio",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate & Store Audio": {
      "main": [
        [
          {
            "node": "Check Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Success": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "pinData": {}
}
